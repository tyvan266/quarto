[
  {
    "objectID": "posts/conditional-aggregation-p1/post.html",
    "href": "posts/conditional-aggregation-p1/post.html",
    "title": "Exercises in Counting",
    "section": "",
    "text": "Life tables are common in actuarial sciences, bio-medical studies, and more generally in the field of survival analysis. They are used to track a dynamic population under observation, one where individuals may enter and leave at different times, and important for computing at-risk rates. In this post, we will demonstrate how to calculate simple life tables from data common in longitudinal clinical trials.\nSuppose we have patient data on enrollment start times (beginning of follow-up) and censoring or death times. For simplicity, instead of using R date types, we will represent start and end times with numeric integer. This set up is similar to our first post on gaps and islands.\n\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(ggplot2)\n\npatient_fup_data &lt;- \n  tibble(\n    ID             = 1:200, \n    startFollowUp  = c(sample(1:200, 200, replace = TRUE)),\n    endDeathCensor = startFollowUp + sample(30:100, 200, replace = TRUE)  \n  )\n\n\nhead(patient_fup_data, n = 10) |&gt; kable()\n\n\n\n\nID\nstartFollowUp\nendDeathCensor\n\n\n\n\n1\n150\n203\n\n\n2\n157\n201\n\n\n3\n55\n143\n\n\n4\n65\n147\n\n\n5\n179\n272\n\n\n6\n23\n96\n\n\n7\n164\n255\n\n\n8\n116\n209\n\n\n9\n11\n74\n\n\n10\n165\n217\n\n\n\n\n\nRoughly, we can visualize when new patients enter and when they leave (due to death or censoring or exiting our risk set). Each segment represents a unique patient and their time segment of observation.\n\n\nCode\nggplot(patient_fup_data |&gt; filter(ID &lt;= 30)) +\n  geom_linerange(\n    aes(xmin = startFollowUp, xmax = endDeathCensor, y = ID)\n    , linewidth = 1) +\n  \n  theme_bw() +\n  xlab(\"Entry / Exit\") +\n  ylab(\"Patient ID\") + \n  \n  theme(\n    axis.text.x = element_text(size = 16, angle = 45),\n    strip.text = element_text(size = 18), \n    axis.title.x = element_text(size = 24),\n    axis.title.y = element_text(size = 24),\n    legend.position = 'right'\n  )\n\n\n\n\n\nObservation time intervals by patients\n\n\n\n\nOur goal is to count over time the current number of patients under observation.\n\n\nIn this method, we will highlight the merging operators left_join and cross_join (also known as cartesian joins).\n\n\n\n\n\n\nWarning\n\n\n\nCartesian joins can be computationally intensive and slow!\n\n\nFirst, we pre-define a grid for time points of interest. Suppose we want to asses counts every 60 time units. The Cartesian join will match every row in the left table (our time point reference) to every row in the right table (our patient data). Then for each patient whose observation window intersects with our index time, we add one:\n\nsurvival_grid &lt;- tibble(xtime = seq(0, 500, 60))\n\nsurv_grid_xpatients &lt;- survival_grid |&gt; cross_join(patient_fup_data)\n\nsurvival_grid_counts &lt;- \nsurv_grid_xpatients |&gt; \n  mutate(count = startFollowUp &lt;= xtime & endDeathCensor &gt;= xtime) |&gt; \n  group_by(xtime) |&gt; \n  summarise(count = sum(count))\n\n\nhead(survival_grid_counts) |&gt; kable()\n\n\n\n\nxtime\ncount\n\n\n\n\n0\n0\n\n\n60\n58\n\n\n120\n70\n\n\n180\n66\n\n\n240\n21\n\n\n300\n0\n\n\n\n\n\n\n\n\nIn this method, we do a rolling count moving through each patient. Eventually we subset on unique entry times where a change in the total population can occur. In particular, at each unique entry time when one or more new patients enroll, we add up the total number of enrollees (a simple row count works here as we cycle through the patient dataset). But we must adjust at each entry the total number lost to death or censoring up to that point. Since more than one patient may enter at the same time, the final numbers in our rolling count appears last by entry times provided we start counting in order from the first entry.\n\nN_under_observation &lt;- \npatient_fup_data |&gt; \n  arrange(startFollowUp) |&gt; \n  \n  mutate(\n    Nenroll = row_number(), \n    Nlost   = map_dbl(startFollowUp, \\(.x) sum(endDeathCensor &lt;= .x)), \n    N_obs   = Nenroll - Nlost \n  ) |&gt; \n  \n  group_by(startFollowUp) |&gt; \n  slice(n()) \n\nFinally, we visualize the change in our patient population size over time.\n\n\nCode\nggplot(N_under_observation, aes(x = startFollowUp, y = N_obs)) + \n  geom_step(size = 1) + \n  xlab(\"Time\") + \n  ylab(\"Number under observation\") + \n  theme_bw() + \n  theme(\n    axis.text.x = element_text(size = 16, angle = 45),\n    strip.text = element_text(size = 18), \n    axis.title.x = element_text(size = 24),\n    axis.title.y = element_text(size = 24),\n    legend.position = 'right'\n  )\n\n\n\n\n\nPopulation size over time"
  },
  {
    "objectID": "posts/conditional-aggregation-p1/post.html#joining-and-cross-method",
    "href": "posts/conditional-aggregation-p1/post.html#joining-and-cross-method",
    "title": "Exercises in Counting",
    "section": "",
    "text": "In this method, we will highlight the merging operators left_join and cross_join (also known as cartesian joins).\n\n\n\n\n\n\nWarning\n\n\n\nCartesian joins can be computationally intensive and slow!\n\n\nFirst, we pre-define a grid for time points of interest. Suppose we want to asses counts every 60 time units. The Cartesian join will match every row in the left table (our time point reference) to every row in the right table (our patient data). Then for each patient whose observation window intersects with our index time, we add one:\n\nsurvival_grid &lt;- tibble(xtime = seq(0, 500, 60))\n\nsurv_grid_xpatients &lt;- survival_grid |&gt; cross_join(patient_fup_data)\n\nsurvival_grid_counts &lt;- \nsurv_grid_xpatients |&gt; \n  mutate(count = startFollowUp &lt;= xtime & endDeathCensor &gt;= xtime) |&gt; \n  group_by(xtime) |&gt; \n  summarise(count = sum(count))\n\n\nhead(survival_grid_counts) |&gt; kable()\n\n\n\n\nxtime\ncount\n\n\n\n\n0\n0\n\n\n60\n58\n\n\n120\n70\n\n\n180\n66\n\n\n240\n21\n\n\n300\n0"
  },
  {
    "objectID": "posts/conditional-aggregation-p1/post.html#map-to-the-rescue",
    "href": "posts/conditional-aggregation-p1/post.html#map-to-the-rescue",
    "title": "Exercises in Counting",
    "section": "",
    "text": "In this method, we do a rolling count moving through each patient. Eventually we subset on unique entry times where a change in the total population can occur. In particular, at each unique entry time when one or more new patients enroll, we add up the total number of enrollees (a simple row count works here as we cycle through the patient dataset). But we must adjust at each entry the total number lost to death or censoring up to that point. Since more than one patient may enter at the same time, the final numbers in our rolling count appears last by entry times provided we start counting in order from the first entry.\n\nN_under_observation &lt;- \npatient_fup_data |&gt; \n  arrange(startFollowUp) |&gt; \n  \n  mutate(\n    Nenroll = row_number(), \n    Nlost   = map_dbl(startFollowUp, \\(.x) sum(endDeathCensor &lt;= .x)), \n    N_obs   = Nenroll - Nlost \n  ) |&gt; \n  \n  group_by(startFollowUp) |&gt; \n  slice(n()) \n\nFinally, we visualize the change in our patient population size over time.\n\n\nCode\nggplot(N_under_observation, aes(x = startFollowUp, y = N_obs)) + \n  geom_step(size = 1) + \n  xlab(\"Time\") + \n  ylab(\"Number under observation\") + \n  theme_bw() + \n  theme(\n    axis.text.x = element_text(size = 16, angle = 45),\n    strip.text = element_text(size = 18), \n    axis.title.x = element_text(size = 24),\n    axis.title.y = element_text(size = 24),\n    legend.position = 'right'\n  )\n\n\n\n\n\nPopulation size over time"
  },
  {
    "objectID": "posts/intro-purrr-map/post.html",
    "href": "posts/intro-purrr-map/post.html",
    "title": "Doing iteration with map (when vectorized functions are not enough)",
    "section": "",
    "text": "Functions in the tidyverse suite of libraries are typically vectorized. They know how to process vector (or list) arguments and return a vector (list) output. This means we get looping-behavior for free without having to explicitly program the looping structure.\n\n\n\n\n\n\nNote\n\n\n\nIn R, vectors are special cases of lists where all elements in the list are of the same atomic type (dbl, char, logical, etc.) — i.e., when they do not hold further objects (or other lists).\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)\n\nset.seed(12345)\n\ndemo_data &lt;- \n  tribble(\n    ~ \"X\", ~ \"Y\", ~ \"Z\",\n    3, 8, 5,\n    2, 4, 7,\n    6, 3, 8,\n    1, 5, 2\n  )\n\n\nFor example, consider the follow demo data:\n\nkable(demo_data)\n\n\n\n\nX\nY\nZ\n\n\n\n\n3\n8\n5\n\n\n2\n4\n7\n\n\n6\n3\n8\n\n\n1\n5\n2\n\n\n\n\n\n\n\nSuppose we want to create a new variable W on the data.frame defined as follows:\n\nif X is less than Y, then W = Z\notherwise, W = 2 * Z\n\nWe can achieve this using the vectorized if_else function wrapped around the mutate method for column creation. Let’s also create the sum of X and Y into V\n\ndemo_data |&gt; \n  mutate(\n    W = if_else(X &lt; Y, Z, 2 * Z),\n    V = X + Y\n  ) |&gt;\n        kable()\n\n\n\n\nX\nY\nZ\nW\nV\n\n\n\n\n3\n8\n5\n5\n11\n\n\n2\n4\n7\n7\n6\n\n\n6\n3\n8\n16\n9\n\n\n1\n5\n2\n2\n6"
  },
  {
    "objectID": "posts/intro-purrr-map/post.html#thresholding-and-counting",
    "href": "posts/intro-purrr-map/post.html#thresholding-and-counting",
    "title": "Doing iteration with map (when vectorized functions are not enough)",
    "section": "Thresholding and counting",
    "text": "Thresholding and counting\nWe demonstrate with a simple application to thresholding. Suppose we have a list of values X, and a smaller list of thresholding values T\n\nlibrary(purrr)\n\nX = c(3, 7, 10, 3, 14, 20, 11, 27)\nT = c(3, 10, 15, 22)\n\nWe want to know, at some threshold of interest, how many values in X fall below the threshold. For the first threshold value 3, we can answer using sum with the vectorized predicate &lt;\n\nX &lt; 3\n\n[1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\nsum(X &lt; 3)\n\n[1] 0\n\n\nTo execute this for all values in our threshold list, we use map_dbl — the first argument is the list of input values we want to loop over (threshold values), and the second argument is an anonymous function over X and parameterized by the threshold argument .t. The final result will match the dimensions of the argument list that we want to run the function over (of size 4).\n\nmap_dbl(T, \\(.t) sum(X &lt; .t))\n\n[1] 0 3 6 7\n\n\n\n\n\n\n\n\nTip\n\n\n\nAn anonymous function, one without a name, is defined in R by \\(.argument) { .body }. Functions are first-class citizens, meaning they can be passed around as arguments into yet other functions."
  },
  {
    "objectID": "posts/intro-purrr-map/post.html#composite-scores-with-missing-values",
    "href": "posts/intro-purrr-map/post.html#composite-scores-with-missing-values",
    "title": "Doing iteration with map (when vectorized functions are not enough)",
    "section": "Composite scores with missing values",
    "text": "Composite scores with missing values\nWe want to compute and track some composite score at each visit. We would like to use the value taken at the visit time, but we’re willing to impute with the closest value 30 days prior. Our composite measure is \\(X + Y\\).\n\npatient_visit_data |&gt; \n1  group_by(ID) |&gt;\n  mutate(\n2    XplusY = map_dbl(VisitDate,\n3      \\(.v)\n        last(\n4          X[VisitDate &lt;= .v & VisitDate &gt;= .v - 30], na_rm = TRUE)\n        +\n        last(\n          Y[VisitDate &lt;= .v & VisitDate &gt;= .v - 30], na_rm = TRUE))\n    \n    ) |&gt; \n  \n5  filter(ID == 2 | ID == 8) |&gt;\n  kable(n = 20)\n\n\n1\n\nTransform the data by processing the variables within patient\n\n\n2\n\nUsing map_dbl to make our composite score of X and Y. Its first argument is the VisitDate column — the list of values we want to loop through or use as input values to our user-defined function\n\n3\n\nThe head of our user-defined function, which will be represented as an anonymous function passed entirely into the second argument of map_dbl. The function is parameterized by the dummy variable .v that will be drawn from the input list\n\n4\n\nThe body of our user-defined anonymous function. Observe it’s a function of the environment variables X and VisitDate scoped from the data.frame context. Note VisitDate used here is independent and different from outer use also in map_dbl!\n\n5\n\nExamine the outputs for patients 2 and 8\n\n\n\n\n\n\n\nID\nVisitDate\nX\nY\nZ\nXplusY\n\n\n\n\n2\n2022-01-12\n24\n92\n48\n116\n\n\n2\n2022-01-15\n34\n113\n47\n147\n\n\n2\n2022-02-20\nNA\n103\n50\nNA\n\n\n2\n2022-03-03\nNA\nNA\nNA\nNA\n\n\n2\n2022-03-15\nNA\n93\n48\nNA\n\n\n2\n2022-04-13\nNA\nNA\n52\nNA\n\n\n2\n2022-05-04\n9\nNA\n55\nNA\n\n\n2\n2022-05-13\n31\nNA\nNA\nNA\n\n\n2\n2022-06-25\n28\n88\nNA\n116\n\n\n2\n2022-06-28\n44\nNA\n59\n132\n\n\n8\n2022-01-02\nNA\nNA\nNA\nNA\n\n\n8\n2022-01-11\n24\n74\n56\n98\n\n\n8\n2022-01-25\n28\nNA\n41\n102\n\n\n8\n2022-02-03\n40\n93\n59\n133\n\n\n8\n2022-02-07\nNA\nNA\n50\n133\n\n\n8\n2022-04-16\n5\n66\n52\n96\n\n\n8\n2022-04-16\n30\nNA\n49\n96\n\n\n8\n2022-05-12\n42\n93\n49\n135\n\n\n8\n2022-05-15\nNA\n102\n52\n144\n\n\n8\n2022-05-23\n27\nNA\nNA\n129\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe function last has an argument called na_rm with default value False. Here, we want the last available measurement recorded when sorted by descending date — which will correspond to the most recent record."
  },
  {
    "objectID": "posts/intro-purrr-map/post.html#map-for-window-aggregations",
    "href": "posts/intro-purrr-map/post.html#map-for-window-aggregations",
    "title": "Doing iteration with map (when vectorized functions are not enough)",
    "section": "Map for window aggregations",
    "text": "Map for window aggregations\nSuppose our next set of tasks are to compute at each scheduled visit\n\nThe average all X values taken within the last 30 days (rolling average of available values)\nThe maximum Y value recorded so far, but excluded the current Y\nThe current value of Z, or the most recent one recorded within the last 10 days\n\n\npatient_visit_with_window_summary &lt;- patient_visit_data |&gt; \n  \n  group_by(ID) |&gt; \n  mutate(\n    \n1    X_30day_average =\n      map_dbl(VisitDate, \n        \\(.v) mean(X[VisitDate &lt;= .v & VisitDate &gt;= .v - 30], na.rm = TRUE)),\n    \n2    Y_max =\n      map_dbl(VisitDate, \n        \\(.v) max(Y[VisitDate &lt;= .v], na.rm = TRUE)),\n    \n3    Z_recent =\n      map_dbl(VisitDate, \n        \\(.v) last(Z[VisitDate &lt;= .v & VisitDate &gt;= .v - 10], na_rm = TRUE))\n    )\n\n\n1\n\n30 day average of X\n\n2\n\nCumulative maximum of Y\n\n3\n\nMost recent Z within the last 10 days\n\n\n\n\nFor each variable, we use map_dbl where the first argument is the VisitDate column (processed within patient) that we want to iterate over as inputs. The user-defined anonymous functions passed into the second argument of map_dbl are functions over the environment variables X, Y, or Z, subset by VisitDate (also scoped separately from the data.frame context) and the dummy variable .v. They eventually reduce the filtered variables using the aggregation functions mean, max, and last.\n\n\nCode\npatient_visit_with_window_summary |&gt; filter(ID == 3 | ID == 7) |&gt;\n  kable(n = 20) |&gt; column_spec(1:7, border_left = TRUE, border_right = TRUE)\n\n\n\n\n\nID\nVisitDate\nX\nY\nZ\nX_30day_average\nY_max\nZ_recent\n\n\n\n\n3\n2022-01-03\n39\nNA\n53\n39.00000\n-Inf\n53\n\n\n3\n2022-01-07\nNA\n105\n53\n39.00000\n105\n53\n\n\n3\n2022-02-24\n16\n78\n49\n16.00000\n105\n49\n\n\n3\n2022-02-25\n35\n109\n50\n25.50000\n109\n50\n\n\n3\n2022-03-27\n48\nNA\n40\n41.50000\n109\n40\n\n\n3\n2022-04-04\n30\n94\n47\n39.00000\n109\n47\n\n\n3\n2022-04-08\n37\n63\nNA\n38.33333\n109\n47\n\n\n3\n2022-04-09\n28\nNA\n52\n35.75000\n109\n52\n\n\n3\n2022-05-25\n36\n103\nNA\n36.00000\n109\nNA\n\n\n3\n2022-06-01\nNA\n89\nNA\n36.00000\n109\nNA\n\n\n7\n2022-01-18\n35\n91\n55\n35.00000\n91\n55\n\n\n7\n2022-02-01\n24\n44\n46\n29.50000\n91\n46\n\n\n7\n2022-02-27\n35\n73\nNA\n29.50000\n91\nNA\n\n\n7\n2022-04-06\n26\n90\n56\n26.00000\n91\n56\n\n\n7\n2022-04-26\n24\n102\n51\n25.00000\n102\n51\n\n\n7\n2022-05-01\nNA\n88\nNA\n25.00000\n102\n51\n\n\n7\n2022-05-12\nNA\n92\nNA\n24.00000\n102\nNA\n\n\n7\n2022-05-15\n56\n90\nNA\n40.00000\n102\nNA\n\n\n7\n2022-05-28\nNA\n64\n54\n56.00000\n102\n54\n\n\n7\n2022-06-16\nNA\n89\n46\nNaN\n102\n46\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen supplying arguments for na.rm or na_rm, always provide the full values TRUE or FALSE instead of using the abbreviated shortcut T or F.\n\n\nTo help spot-check the results (particularly for the rolling 30-day look-back averages), use the general map to get a list of values meeting the condition at each visit (list of lists!) prior to aggregation by mean. For Z_recent, you may want to validate that the 10-day look-back is working as expected.\n\npatient_visit_with_window_summary &lt;- patient_visit_data |&gt; \n  \n  group_by(ID) |&gt;\n  \n  mutate(\n    \n1    Xs_30day = map(VisitDate, \\(.v) X[VisitDate &lt;= .v & VisitDate &gt;= .v - 30]),\n    \n    X_30day_average = \n      map_dbl(VisitDate, \n        \\(.v) mean(X[VisitDate &lt;= .v & VisitDate &gt;= .v - 30], na.rm = TRUE)),\n    \n    Y_max = \n      map_dbl(VisitDate, \n        \\(.v) max(Y[VisitDate &lt;= .v], na.rm = TRUE)),\n    \n    Z_recent = \n      map_dbl(VisitDate, \n        \\(.v) last(Z[VisitDate &lt;= .v & VisitDate &gt;= .v - 10], na_rm = TRUE))\n    \n    ) \n\n\n1\n\nNow our anonymous function filters X using the VisitDate column and the index visit date .v, but does not summarize the vector further. Instead of returning a dbl value at each execution (like map_dbl), it must return back an entire list at each call. Hence, in the end map returns a vector of lists.\n\n\n\n\n\n\nCode\npatient_visit_with_window_summary |&gt; filter(ID == 3 | ID == 7) |&gt;\n    kable(n = 20) |&gt; column_spec(1:8, border_left = TRUE, border_right = TRUE)\n\n\n\n\n\nID\nVisitDate\nX\nY\nZ\nXs_30day\nX_30day_average\nY_max\nZ_recent\n\n\n\n\n3\n2022-01-03\n39\nNA\n53\n39\n39.00000\n-Inf\n53\n\n\n3\n2022-01-07\nNA\n105\n53\n39, NA\n39.00000\n105\n53\n\n\n3\n2022-02-24\n16\n78\n49\n16\n16.00000\n105\n49\n\n\n3\n2022-02-25\n35\n109\n50\n16, 35\n25.50000\n109\n50\n\n\n3\n2022-03-27\n48\nNA\n40\n35, 48\n41.50000\n109\n40\n\n\n3\n2022-04-04\n30\n94\n47\n48, 30\n39.00000\n109\n47\n\n\n3\n2022-04-08\n37\n63\nNA\n48, 30, 37\n38.33333\n109\n47\n\n\n3\n2022-04-09\n28\nNA\n52\n48, 30, 37, 28\n35.75000\n109\n52\n\n\n3\n2022-05-25\n36\n103\nNA\n36\n36.00000\n109\nNA\n\n\n3\n2022-06-01\nNA\n89\nNA\n36, NA\n36.00000\n109\nNA\n\n\n7\n2022-01-18\n35\n91\n55\n35\n35.00000\n91\n55\n\n\n7\n2022-02-01\n24\n44\n46\n35, 24\n29.50000\n91\n46\n\n\n7\n2022-02-27\n35\n73\nNA\n24, 35\n29.50000\n91\nNA\n\n\n7\n2022-04-06\n26\n90\n56\n26\n26.00000\n91\n56\n\n\n7\n2022-04-26\n24\n102\n51\n26, 24\n25.00000\n102\n51\n\n\n7\n2022-05-01\nNA\n88\nNA\n26, 24, NA\n25.00000\n102\n51\n\n\n7\n2022-05-12\nNA\n92\nNA\n24, NA, NA\n24.00000\n102\nNA\n\n\n7\n2022-05-15\n56\n90\nNA\n24, NA, NA, 56\n40.00000\n102\nNA\n\n\n7\n2022-05-28\nNA\n64\n54\nNA, NA, 56, NA\n56.00000\n102\n54\n\n\n7\n2022-06-16\nNA\n89\n46\nNA, NA\nNaN\n102\n46"
  },
  {
    "objectID": "posts/map-overlapping-dates/post.html",
    "href": "posts/map-overlapping-dates/post.html",
    "title": "Overlapping intervals",
    "section": "",
    "text": "The Puzzle\nThe overlapping intervals puzzle is similar in spirit to the overlapping date ranges problem, and structurally like the gaps and islands problem. (link to previous post)\nWe can think of it as a variant of the same problem. Here, instead of using proper date types, we will work with integers to represent intervals, or start and end markers.\nOur solution will use the map function, introduced in (previous post). Here we also add a new extension, before we used map in the context of single list of input values, where essentially we wanted to iterate it through a function parameterized by one argument. Now we consider map2_dbl (and its variants) where we want to use multiple lists of input values to be used simultaneously\nApplications are also similar in spirit. Consider for example, intervals representing medication start and end.\nUnlike the gaps and islands, we add one new wrinkle: a type field that distinguishes between different intervals. We can think as different medication drugs. Then, one application is now checking for concomittant use, or overlapping use.\nOther applications might include:\n\noverlapping diseases or medical conditions\noverlapping stays or visits or other events generally\noverlapping service or programs\n\n\nlibrary(tidyverse)\nlibrary(ggplot2)\n\ndemo_data &lt;- \n  tribble(\n    ~ \"ID\", ~ \"Begin\", ~ \"End\", ~ \"Type\",\n       1      ,12       , 18     ,\"A\"   ,\n       1      ,20       , 25     ,\"B\"   ,\n       1      ,23       , 30     ,\"C\"   ,\n       2      ,7        , 13     ,\"A\"   ,\n       2      ,12       , 20     ,\"B\"   ,\n       3      ,18       , 28     ,\"A\"   ,\n       3      ,20       , 33     ,\"B\"   ,\n       3      ,31       , 42     ,\"C\"   ,\n       3      ,44       , 50     ,\"D\"   ,\n       4      ,10       , 25     ,\"A\"   ,\n       4      ,15       , 19     ,\"B\"   ,\n       4      ,21       , 30     ,\"C\"   ,\n       5      ,3        , 8      ,\"A\"   ,\n       5      ,7        , 15     ,\"B\"   ,\n       5      ,13       , 22     ,\"C\"   ,\n       5      ,19       , 26     ,\"D\"   ,\n       5      ,25       , 33     ,\"E\"\n  ) |&gt; \n  mutate(ID = factor(ID))\n\nSimilar interval range data\n\n\nCode\nggplot(\n  demo_data |&gt; \n  group_by(ID) |&gt; \n  mutate(y = row_number())\n  , aes(y=y, color=Type)) +\n  \n  geom_linerange(\n    aes(xmin = Begin, xmax = End, y=y)\n    , linewidth = 2\n  ) + \n  \n  #geom_point(aes(x = Begin, y = 0, label = Type)) + \n  \n  scale_color_brewer(palette = \"Set1\") + \n  \n  xlab(\"Begin/ End\") + ylab(\"ID Panels\") +\n  scale_x_continuous(breaks = seq(0,50,5)) + \n\n  theme_bw() +\n  \n  geom_label(\n    aes(x = Begin, y=y, label = Type, group = ID)\n    , position = position_nudge(y = .5) \n    , size = 8\n  ) +\n  \n  facet_wrap(. ~ ID, scale = 'free_y') + \n  \n  theme(\n    axis.text.x = element_text(size = 16, angle = 45),\n    axis.text.y = element_blank(),\n    strip.text = element_text(size = 18), \n    axis.title.x = element_text(size = 24),\n    axis.title.y = element_text(size = 24)\n    , legend.position = 'none'\n  )\n\n\n\n\n\n\n\nSolution using map\nFor each interval, we loop through their Start and End and subset the intervals from Type list that satisfying the corresponding conditions on their starts and ends.\n\ndemo_data |&gt; \n  group_by(ID) |&gt; \n  arrange(ID, Begin) |&gt; \n  mutate(\n    findOverlaps = \n      map2_chr(Begin, End, \\(.x, .y) str_c(Type[!(.x &gt;= End | .y &lt;= Begin)], collapse = \" & \"))\n  )\n\n# A tibble: 17 × 5\n# Groups:   ID [5]\n   ID    Begin   End Type  findOverlaps\n   &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;       \n 1 1        12    18 A     A           \n 2 1        20    25 B     B & C       \n 3 1        23    30 C     B & C       \n 4 2         7    13 A     A & B       \n 5 2        12    20 B     A & B       \n 6 3        18    28 A     A & B       \n 7 3        20    33 B     A & B & C   \n 8 3        31    42 C     B & C       \n 9 3        44    50 D     D           \n10 4        10    25 A     A & B & C   \n11 4        15    19 B     A & B       \n12 4        21    30 C     A & C       \n13 5         3     8 A     A & B       \n14 5         7    15 B     A & B & C   \n15 5        13    22 C     B & C & D   \n16 5        19    26 D     C & D & E   \n17 5        25    33 E     D & E"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Sieving Data, A Quarto Blog",
    "section": "",
    "text": "Exercises in Counting\n\n\n\n\n\nApplication to survival analysis\n\n\n\n\n\n\nApr 10, 2024\n\n\n\n\n\n\n  \n\n\n\n\nThinking about event frequencies\n\n\n\n\n\nDescribing rates over time\n\n\n\n\n\n\nNov 11, 2023\n\n\n\n\n\n\n  \n\n\n\n\nOverlapping intervals\n\n\n\n\n\nCase study with map\n\n\n\n\n\n\nOct 26, 2023\n\n\n\n\n\n\n  \n\n\n\n\nDescribing time series data\n\n\n\n\n\nApplication to Bitcoin financial price\n\n\n\n\n\n\nOct 24, 2023\n\n\n\n\n\n\n  \n\n\n\n\nDoing iteration with map (when vectorized functions are not enough)\n\n\n\n\n\nApplication to window functions and computing composite scores with missing values\n\n\n\n\n\n\nOct 11, 2023\n\n\n\n\n\n\n  \n\n\n\n\nThe Gaps and Islands Problem\n\n\n\n\n\nAlso known as the overlapping-date-ranges problem, where we study duration data to identify coverage intervals (or, holes)\n\n\n\n\n\n\nOct 4, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "A collection of posts on data management principles using R for the aspiring programmer."
  },
  {
    "objectID": "posts/gaps-and-islands/post.html",
    "href": "posts/gaps-and-islands/post.html",
    "title": "The Gaps and Islands Problem",
    "section": "",
    "text": "The gaps and islands problem arises from analyzing duration data as commonly captured in databases. Duration data are events recorded with a start datetime and end datetime. Rows in the table correspond to unique events that someone is experiencing, or during which times the event is active. As individuals ID may have one or more event activity, such data are often stored in long-form as date ranges or intervals.\n\n\n\n\n\n\nNote\n\n\n\nFor simplicity, we assume only one type of event under study — the data can be generalized to include an event-type field.\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)\n\nset.seed(12345)\n\n# 10 individuals\nID &lt;- 1:10\n\n# 3 to 7 events per person \nn_events &lt;- sample(3:7, 10, replace = TRUE)\n\nduration_data &lt;- tibble(ID = rep(ID, n_events)) |&gt; \n  mutate(\n    start_date = \n      sample(seq(as.Date('2022-01-01'), as.Date('2022-12-31'), by = \"day\"), n(), replace = TRUE),\n    # 3 days - 2 months episodes \n    end_date = start_date + sample(3:60, n(), replace = TRUE)   \n  ) |&gt; \n  arrange(ID, start_date) |&gt; \n  group_by(ID) |&gt; \n  mutate(eventID = row_number())\n\n\nFor example:\n\nhead(duration_data, n=15) |&gt; kable()\n\n\n\n\nID\nstart_date\nend_date\neventID\n\n\n\n\n1\n2022-02-09\n2022-03-06\n1\n\n\n1\n2022-07-31\n2022-08-09\n2\n\n\n1\n2022-09-14\n2022-11-10\n3\n\n\n1\n2022-10-13\n2022-11-10\n4\n\n\n1\n2022-10-21\n2022-11-23\n5\n\n\n2\n2022-01-12\n2022-02-20\n1\n\n\n2\n2022-01-14\n2022-02-08\n2\n\n\n2\n2022-09-16\n2022-11-03\n3\n\n\n2\n2022-11-24\n2022-12-11\n4\n\n\n3\n2022-01-16\n2022-01-23\n1\n\n\n3\n2022-03-21\n2022-05-05\n2\n\n\n3\n2022-04-16\n2022-05-23\n3\n\n\n3\n2022-05-21\n2022-06-04\n4\n\n\n3\n2022-05-28\n2022-06-23\n5\n\n\n3\n2022-07-11\n2022-08-08\n6\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo reveal the code how to simulate the demo data, click the Code text to expand above.\n\n\nHere, ID 1 experiences 5 distinct eventIDs, with the first one occurring on 2/9 and lasting for 25 days until 3/6. The key observation is that eventID 4 overlaps with eventID 5 within ID 1, where event 5 beginning on 10/21 starts before event 4 has ended on 11/10.\n\n\nVisualizing the date ranges of event occurrences is useful. We plot all individual event date ranges colored by ID, supplying a position_dodge so overlaps are revealed (instead of lying right on top one another).\n\n\nCode\nlibrary(ggplot2)\n\nggplot(duration_data |&gt; filter(ID &lt;= 5),\n       aes(y = factor(ID), xmin = start_date, xmax = end_date, color = factor(ID))) +\n  geom_linerange(position = position_dodge2(width = .5), linewidth = 2) +\n  theme_bw() + \n  xlab(\"Start/ End Dates\") + ylab(\"Individual ID\") +\n  scale_x_date(date_breaks = \"1 month\") + \n  theme(\n    axis.text.x = element_text(size = 16, angle = 45),\n    axis.text.y = element_text(size = 16),\n    axis.title.x = element_text(size = 24),\n    axis.title.y = element_text(size = 24),\n    legend.position = 'none'\n  )\n\n\n\n\n\nDuration patterns by subject\n\n\n\n\n\n\n\nGiven the set-up, how do we want to collapse the data? Our input data is structured as one row per date range per person. The desired output data is one row per coverage interval per person. By coverage, we mean a continuous block of time, defined by a start date and end date, during which the individual is experiencing one or more active events.\n\n\n\n\n\n\nNote\n\n\n\nCoverage intervals are referred to as islands. In-between time periods when there are no events occurring (no date ranges, overlapping or otherwise) are called gaps (holes).\n\n\nFor our demo data, within ID 2, there are 4 eventIDs, but just 3 coverage intervals (islands): some event is active between\n\n2022-01-12 through 2022-02-08 (where the date range of event 2 completely overlaps and within the duration time of event 1)\n2022-09-16 through 2022-11-03 (duration of eventID 3)\n2022-11-24 through 2022-12-11 (duration of last eventID 4)\n\nHence our desired output table will comprise 3 rows for ID 2, with start and end times as described above for each coverage interval. Likewise, by visual inspection, ID 3, who experienced 6 events, will have only 3 coverage intervals as well, with one particularly long coverage interval (of back-to-back events) beginning on 2022-03-21 and finally abating on 2022-06-23.\n\n\n\nExamining the gaps and islands solution can reveal hidden assumptions about data processes or quality issues you might not be aware of. For example, perhaps certain overlap patterns violate assumptions about event frequencies, or some duration lengths and patterns are not physically possible. Typically, the data captured does not reflect the complete story.\nConsider medical databases housing patient medication prescriptions. The table captures PatientID, DispensedDate, and DaysSupply, from which an EndDate is derived representing date of supply depletion relative to dispense time. The data as entered by pharmacists or business administrators for billing purposes or inventory management is only one part of the story, especially if our goal is to understand how patients are treated.\nFor example, suppose we observe multiple overlapping prescriptions for the same medication type (overlapping date ranges), but perhaps differing dose levels. It is not clear whether the patient has been instructed to take both prescriptions simultaneously (effective dose increase), or perhaps to switch to the lower dose before finishing the other prescription. We have missing contextual information! And, if we observe overlapping date ranges among different medication types, we may find new or surprising treatment regimes warranting investigation.\nIf we know what we see is impossible, and we have high assurance of data validity (they were not entered erroneously), we investigate further. Perhaps, it turns out a subset of prescriptions were returned-to-stock and were never picked up by the patient, requiring a check on another data field that we were not aware was being captured. With data in the wild, as we’re removed further away from the source of data origination, incomplete code-books, inaccurate code-books, or non-existent code-books represent the norm.\n\n\n\n\n\n\nNote\n\n\n\nUnless we already know what to look for, generalizing how we describe event patterns can help reveal new information requiring follow-up."
  },
  {
    "objectID": "posts/gaps-and-islands/post.html#visualization",
    "href": "posts/gaps-and-islands/post.html#visualization",
    "title": "The Gaps and Islands Problem",
    "section": "",
    "text": "Visualizing the date ranges of event occurrences is useful. We plot all individual event date ranges colored by ID, supplying a position_dodge so overlaps are revealed (instead of lying right on top one another).\n\n\nCode\nlibrary(ggplot2)\n\nggplot(duration_data |&gt; filter(ID &lt;= 5),\n       aes(y = factor(ID), xmin = start_date, xmax = end_date, color = factor(ID))) +\n  geom_linerange(position = position_dodge2(width = .5), linewidth = 2) +\n  theme_bw() + \n  xlab(\"Start/ End Dates\") + ylab(\"Individual ID\") +\n  scale_x_date(date_breaks = \"1 month\") + \n  theme(\n    axis.text.x = element_text(size = 16, angle = 45),\n    axis.text.y = element_text(size = 16),\n    axis.title.x = element_text(size = 24),\n    axis.title.y = element_text(size = 24),\n    legend.position = 'none'\n  )\n\n\n\n\n\nDuration patterns by subject"
  },
  {
    "objectID": "posts/gaps-and-islands/post.html#what-do-we-wish-to-solve-for",
    "href": "posts/gaps-and-islands/post.html#what-do-we-wish-to-solve-for",
    "title": "The Gaps and Islands Problem",
    "section": "",
    "text": "Given the set-up, how do we want to collapse the data? Our input data is structured as one row per date range per person. The desired output data is one row per coverage interval per person. By coverage, we mean a continuous block of time, defined by a start date and end date, during which the individual is experiencing one or more active events.\n\n\n\n\n\n\nNote\n\n\n\nCoverage intervals are referred to as islands. In-between time periods when there are no events occurring (no date ranges, overlapping or otherwise) are called gaps (holes).\n\n\nFor our demo data, within ID 2, there are 4 eventIDs, but just 3 coverage intervals (islands): some event is active between\n\n2022-01-12 through 2022-02-08 (where the date range of event 2 completely overlaps and within the duration time of event 1)\n2022-09-16 through 2022-11-03 (duration of eventID 3)\n2022-11-24 through 2022-12-11 (duration of last eventID 4)\n\nHence our desired output table will comprise 3 rows for ID 2, with start and end times as described above for each coverage interval. Likewise, by visual inspection, ID 3, who experienced 6 events, will have only 3 coverage intervals as well, with one particularly long coverage interval (of back-to-back events) beginning on 2022-03-21 and finally abating on 2022-06-23."
  },
  {
    "objectID": "posts/gaps-and-islands/post.html#application-in-medicine",
    "href": "posts/gaps-and-islands/post.html#application-in-medicine",
    "title": "The Gaps and Islands Problem",
    "section": "",
    "text": "Examining the gaps and islands solution can reveal hidden assumptions about data processes or quality issues you might not be aware of. For example, perhaps certain overlap patterns violate assumptions about event frequencies, or some duration lengths and patterns are not physically possible. Typically, the data captured does not reflect the complete story.\nConsider medical databases housing patient medication prescriptions. The table captures PatientID, DispensedDate, and DaysSupply, from which an EndDate is derived representing date of supply depletion relative to dispense time. The data as entered by pharmacists or business administrators for billing purposes or inventory management is only one part of the story, especially if our goal is to understand how patients are treated.\nFor example, suppose we observe multiple overlapping prescriptions for the same medication type (overlapping date ranges), but perhaps differing dose levels. It is not clear whether the patient has been instructed to take both prescriptions simultaneously (effective dose increase), or perhaps to switch to the lower dose before finishing the other prescription. We have missing contextual information! And, if we observe overlapping date ranges among different medication types, we may find new or surprising treatment regimes warranting investigation.\nIf we know what we see is impossible, and we have high assurance of data validity (they were not entered erroneously), we investigate further. Perhaps, it turns out a subset of prescriptions were returned-to-stock and were never picked up by the patient, requiring a check on another data field that we were not aware was being captured. With data in the wild, as we’re removed further away from the source of data origination, incomplete code-books, inaccurate code-books, or non-existent code-books represent the norm.\n\n\n\n\n\n\nNote\n\n\n\nUnless we already know what to look for, generalizing how we describe event patterns can help reveal new information requiring follow-up."
  },
  {
    "objectID": "posts/map-ts-btc/post.html",
    "href": "posts/map-ts-btc/post.html",
    "title": "Describing time series data",
    "section": "",
    "text": "Period indicators\nData over time\nOne row per day, month, year, etc.\nSometimes level is too fine.. we want to summarize more coarsely, say monthly or weekly\nTrick: create period indicators, use regression for basic averages\n\n\nCode\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)\n\nset.seed(12345)\n\nbtc &lt;- \n  read_csv('BTC-USD.csv')           |&gt;\n  select(Date, Close)               |&gt; \n  mutate(Close = as.numeric(Close)) |&gt; \n  filter(\n    Date &lt;= as.Date('2023-10-22', '%Y-%m-%d'))\n\nbtc_monthly_indicator &lt;- \nbtc |&gt; \n  mutate(m = month(Date)) \n\n\nbtc_monthly_indicator |&gt; sample_n(size = 10) |&gt;  kable() \n\n\n\n\n\nDate\nClose\nm\n\n\n\n\n2023-05-22\n26851.28\n5\n\n\n2023-02-20\n24829.15\n2\n\n\n2023-07-27\n29210.69\n7\n\n\n2023-08-06\n29041.86\n8\n\n\n2023-08-08\n29765.49\n8\n\n\n2023-06-01\n26819.97\n6\n\n\n2023-04-03\n27790.22\n4\n\n\n2023-03-16\n25052.79\n3\n\n\n2023-08-04\n29074.09\n8\n\n\n2023-09-15\n26608.69\n9\n\n\n\n\n\n\n\nRun basic regression, use predict to get fitted values. Graph and overlay\nMonths as categorical variables (factors)\n\nbtc_fit &lt;- lm(Close ~ factor(m), data = btc_monthly_indicator)\n\nbtc_monthly_indicator$fit &lt;- predict.lm(btc_fit, btc_monthly_indicator)\n\nbtc_monthly_indicator |&gt; sample_n(size = 10) |&gt;  kable() \n\n\n\n\nDate\nClose\nm\nfit\n\n\n\n\n2023-03-27\n27139.89\n3\n25116.90\n\n\n2023-03-16\n25052.79\n3\n25116.90\n\n\n2023-02-07\n23264.29\n2\n23304.54\n\n\n2023-04-13\n30399.07\n4\n28857.57\n\n\n2023-09-23\n26579.39\n9\n26306.14\n\n\n2023-02-09\n21819.04\n2\n23304.54\n\n\n2023-10-13\n26862.38\n10\n27958.07\n\n\n2023-09-14\n26539.67\n9\n26306.14\n\n\n2023-07-31\n29230.11\n7\n30057.47\n\n\n2023-01-12\n18869.59\n1\n20250.72\n\n\n\n\n\n\n\nGraph the price data, overlay with fitted values from the model\n\nggplot(btc_monthly_indicator, aes(x = Date, y = Close)) + \n  geom_point(size = 1) +\n  geom_line(size = .8) +\n  \n  geom_line(aes(x = Date, y = fit), linewidth = 1, color = \"red\") + \n  \n  scale_y_continuous(breaks = seq(16000, 32000, 1000)) +\n  scale_x_date(breaks = \"1 month\") + \n  \n  theme_bw()\n\n\n\n\nConfirm that, using monthly indicators is the same as just computing the average monthly price\n\nbtc_monthly_avg &lt;- \n  btc_monthly_indicator |&gt; \n  group_by(m)           |&gt; \n  summarise(Close = mean(Close))\n\nbtc_monthly_avg$Date &lt;- seq.Date(from = as.Date('2023-01-15'), to = as.Date('2023-10-15'), length.out = 10)\n\nNow overlay these monthly averages onto the plot\n\nggplot(btc_monthly_indicator, aes(x = Date, y = Close)) + \n  geom_point(size = 1) +\n  geom_line(size = .8) +\n  \n  geom_line(aes(x = Date, y = fit), linewidth = 1, color = \"red\") + \n  \n  geom_point(btc_monthly_avg, mapping=aes(x = Date, y = Close), size = 5, shape = 1, color = 'blue') +\n  \n  scale_y_continuous(breaks = seq(16000, 32000, 1000)) +\n  scale_x_date(breaks = \"1 month\") + \n  \n  \n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nDespite their underlying statistical assumptions, models can be used for descriptive summaries (exploratory analyses). Inference is a different story!\n\n\n\n\nSmoothers\nRolling averages\nIn finance, 2 weeks, 1 month, 3 months\n\nbtc_rolling_means &lt;- \nbtc |&gt; \n  mutate(\n    roll_1week = map_dbl(Date, \\(.x) mean(Close[Date &lt;= .x & Date &gt;= .x - 7])),\n    roll_1mon  = map_dbl(Date, \\(.x) mean(Close[Date &lt;= .x & Date &gt;= .x - 30])),\n    roll_3mon  = map_dbl(Date, \\(.x) mean(Close[Date &lt;= .x & Date &gt;= .x - 90]))\n  )\n\nPlot it\n\nggplot(btc_rolling_means, aes(x = Date, y = Close)) + \n  geom_point(size = 1) +\n  geom_line(size = .8) +\n  \n  geom_line(aes(y = roll_1week), linewidth = 1, color = \"red\") + \n  geom_line(aes(y = roll_1mon), linewidth = 1, color = \"blue\") + \n  geom_line(aes(y = roll_3mon), linewidth = 1, color = \"orange\") + \n\n  scale_y_continuous(breaks = seq(16000, 32000, 1000)) +\n  scale_x_date(breaks = \"1 month\") + \n  \n  \n  theme_bw()\n\n\n\n\nHow does volatility change over time?"
  },
  {
    "objectID": "posts/event-freqs/post.html",
    "href": "posts/event-freqs/post.html",
    "title": "Thinking about event frequencies",
    "section": "",
    "text": "Events over time\nConsider longitudinal data in long-format, each row representing an event occurrence at some date\nFor simplicity, suppose we have 5 subjects, and each subject experiences some number of events between 10 - 20, occuring within a 5 year time frame from 2015 - 2020.\nIn medicine, such events may represent: doctor visits, treatment times, exposure incidences, etc.\n\n\nCode\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(ggplot2)\n\nset.seed(12345)\n\nevent_num &lt;- sample(5:15, 5, replace = T)\nN_rows    &lt;- sum(event_num) \n\n\npt_events &lt;- \n  data.frame(\n    ID = rep(1:5, event_num), \n    # random occurrences \n    EventDate = sample(seq(as.Date('2015-01-01'), as.Date('2020-01-01'), by = \"day\"), N_rows)\n  )\n\n\nA quick way to get a glimpse for the patterns of event occurrences is to plot them by patient (subject) using dots to represent along the x-axis the relative timing of event occurrences.\n\nggplot(pt_events, aes(x = EventDate, y = ID, color = factor(ID))) + \n  geom_point(size = 2) + \n  geom_line(linewidth = 1) \n\n\n\n\nAlthough we generated events uniformly over the times, interesting patterns can still emerge. Within patients, events may cluster closer to the beginning or end of the study period. Some patients may appear to have occurences mroe regularly or evenly spaced, while others have relatively few occurrences in total.\nThere are a variety of ways to describe the event rates, with the goal to communicate a general sense of activity levels. Depending on the problem, we may develop different inclusion/ exclusion criterions.\n\n\nAnnualized rate\nA simple metric, but ignores potential clustering effects. Defined by\n\\[ total events / number of years \\]\n\n\nAverage time between events\nThis provides a closer sense of the regularity.\n\n\nMaximum time between two consecutive events\nThis gets at the evenness (?) more or frequency per time ?, and often used for inclusion criterion. If the max time is less than 1 year, then it must be the case that patients are having activity at least every year.\nSometimes people talk about a rolling time frame, which is just like a sliding time window: there is always some event within a one year window over the period of question. Usually the motivation is capture some notion of consistency\n\n\nMinimum time between two consecutive events\nEvents of the same type appearing too close together may be sources of error, noise, or other uncertainty. Here, subject matter knowledge is important. For example, if there events are weight measurements, then we do not expect values event a few short days apart to be very different, and instead want to attribute such observed differences as noise, and may apply a smoothing operation to values in a short window, in the end pegging the event date perhaps to the earliest time, latest time, of middle time within the window."
  }
]