[
  {
    "objectID": "posts/conditional-aggregation-p1/post.html",
    "href": "posts/conditional-aggregation-p1/post.html",
    "title": "When vectorized functions are not enough: using map for iteration",
    "section": "",
    "text": "Basics of mapping functions\nOrdinarily, dplyr functions operate on entire vectors of data, or lists when accessing data.frame column names\n\n\n\n\n\n\nImportant\n\n\n\nIn tidyverse functions, what we may perceive as row-wise operations, functions acting on the scalar values taken from two or more columns, are actually vectorized functions that are acting on the entire set of column values.\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)\n\nset.seed(12345)\n\ndemo_data &lt;- \n  tribble(\n    ~ \"X\", ~ \"Y\", ~ \"Z\",\n    3, 8, 5,\n    2, 4, 7,\n    6, 3, 8,\n    1, 5, 2\n  )\n\n\nConsider the follow demo data:\n\nkable(demo_data)\n\n\n\n\nX\nY\nZ\n\n\n\n\n3\n8\n5\n\n\n2\n4\n7\n\n\n6\n3\n8\n\n\n1\n5\n2\n\n\n\n\n\n\n\nWhen we create a new column via mutate say for the sum of X and Y, or even X + 1, it’s tempting to think the operation is happening row by row as the return list is being created.\n\ndemo_data |&gt; \n  mutate(\n    Sum    = X + Y, \n    Xplus1 = X + 1\n  ) |&gt; kable() \n\n\n\n\nX\nY\nZ\nSum\nXplus1\n\n\n\n\n3\n8\n5\n11\n4\n\n\n2\n4\n7\n6\n3\n\n\n6\n3\n8\n9\n7\n\n\n1\n5\n2\n6\n2\n\n\n\n\n\n\n\nBut the return columns are list types themselves, and it’s more useful to remember that our functions are taking in one set of list types arguments as returning another.\nBut instead, we may actually want to proceed row-wise at least along one column, while processing the list column of another field. We want to manipulate columns while using values and scalars from other columns. For example, one column act as a list of arguments or parameters, and we want to use the current value as a scalar input to aggregate over another column taken a list type.\nInstead, consider the following task: Create a new column W where for each value of X, we sum all values of Y but after having multiplied them by the current X scalar value.\nWe can get this to work by hand:\n\ndemo_data$X[1]  \n\n[1] 3\n\ndemo_data$X[1] * demo_data$Y\n\n[1] 24 12  9 15\n\nsum(demo_data$X[1] * demo_data$Y) \n\n[1] 60\n\n\nIf our brains continue to think things work row-by-row, we may be led astray with an incorrect first attempt:\n\ndemo_data |&gt; \n  mutate(\n    W = sum(X * Y)) |&gt; kable() \n\n\n\n\nX\nY\nZ\nW\n\n\n\n\n3\n8\n5\n55\n\n\n2\n4\n7\n55\n\n\n6\n3\n8\n55\n\n\n1\n5\n2\n55\n\n\n\n\n\n\n\nBecause W return type must be a list, but the function operations are aggregating over other list types, it just repeats the same value along each row. But we don’t want it to act on X as a vector.\n\n\n\n\n\n\nTip\n\n\n\nA scalar is a one-dimensional data type (compared to matrices, lists, data.frames, objects, etc.). Simply, a scalar is a singular value or number, and that’s all — 2 is scalar, but the vector containing the single element two, [2], is not.\n\n\nIntroduce map_dbl. The first argument is a list, and the second argument is a function of the scalar value extracted along the list, and along with other data lists taken from the data.frame environment. Hence it will return a new vector, one dbl result for processing each value in the list input, and this satisfies the return type that mutate is returning an entire vector output matching the dimensions of the original data.frame\n\ndemo_data |&gt; \n  mutate(\n    W = map_dbl(X, \\(.x) sum(.x * Y))) |&gt; kable() \n\n\n\n\nX\nY\nZ\nW\n\n\n\n\n3\n8\n5\n60\n\n\n2\n4\n7\n40\n\n\n6\n3\n8\n120\n\n\n1\n5\n2\n20\n\n\n\n\n\n\n\nOur anonymous function uses the entire Y list as input to it’s processing. The .x argument must be a scalar because it is drawn from X within the use of map_dbl, which will run the function for each value of X, putting the result into a return list W\n\n\nWarm-up: Leave-one-out comparisons\nWithin group, compare to means of the others…\nLet’s generate some data by group, where maybe observations different from the rest. drawn from a mixture of distributions of sort.\n\n# 100 rnorm \nx &lt;- rnorm(90)\ny &lt;- rep(5, 10)\n\ndemo_grp_data &lt;-\n  tibble(\n    ID = rep(1:10, 10),\n    v = sample(c(x,y), replace = F)\n  )\n\nFor each observation within ID, we want to compute the absolute difference between the observation under consideration, with the mean of the rest of the observations in the group.\n\ndemo_grp_data |&gt; \n  group_by(ID) |&gt; \n  mutate(\n    X = map_dbl(v, \\(.x) (sum(v) - .x)/(length(v) - 1)) \n  ) |&gt; \n  \n  arrange(ID) \n\n# A tibble: 100 × 3\n# Groups:   ID [10]\n      ID       v     X\n   &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1     1 -1.34   0.503\n 2     1  0.0546 0.348\n 3     1  0.517  0.296\n 4     1  0.888  0.255\n 5     1  1.46   0.192\n 6     1  0.943  0.249\n 7     1  0.854  0.259\n 8     1  0.254  0.326\n 9     1  0.620  0.285\n10     1 -1.06   0.472\n# ℹ 90 more rows\n\n\n\n\nBrain teaser level:\nOverlapping intervals again, with reference to current: say, find all concomittant drugs\nFake data example. This is similar to the overlapping date ranges problem, but here we each interval act as its own reference or index point from which we want to compare. Instead of using proper datetypes, we use numeric Begin and End for simplicity.\n\ndemo_data &lt;- \n  tribble(\n    ~ \"ID\", ~ \"Begin\", ~ \"End\", ~ \"Type\",\n       1      ,12       , 18     ,\"A\"   ,\n       1      ,20       , 25     ,\"B\"   ,\n       1      ,23       , 30     ,\"C\"   ,\n       2      ,7        , 13     ,\"A\"   ,\n       2      ,12       , 20     ,\"B\"   ,\n       3      ,18       , 28     ,\"A\"   ,\n       3      ,20       , 33     ,\"B\"   ,\n       3      ,31       , 42     ,\"C\"   ,\n       3      ,44       , 50     ,\"D\"   ,\n       4      ,10       , 25     ,\"A\"   ,\n       4      ,15       , 19     ,\"B\"   ,\n       4      ,21       , 30     ,\"C\"   ,\n       5      ,3        , 8      ,\"A\"   ,\n       5      ,7        , 15     ,\"B\"   ,\n       5      ,13       , 22     ,\"C\"   ,\n       5      ,19       , 26     ,\"D\"   ,\n       5      ,25       , 33     ,\"E\"\n  ) |&gt; \n  mutate(ID = factor(ID))\n\nSimilar interval range data\n\n\nCode\nggplot(demo_data, aes(color = Type)) +\n  geom_linerange(\n    aes(xmin = Begin, xmax = End, y = 0)\n    , linewidth = 2\n    , position = position_dodge2(width = .5)) + \n  scale_color_brewer(palette = \"Set1\") + \n  \n  xlab(\"Begin/ End\") + ylab(\"ID Panels\") +\n  scale_x_continuous(breaks = seq(0,50,5)) + \n\n  theme_bw() +\n  \n  facet_grid(ID ~ .) + \n  \n  theme(\n    axis.text.x = element_text(size = 16, angle = 45),\n    axis.text.y = element_blank(),\n    strip.text = element_text(size = 18), \n    axis.title.x = element_text(size = 24),\n    axis.title.y = element_text(size = 24),\n    legend.position = 'right'\n  )\n\n\n\n\n\nSolution\nFor each interval, we loop through their Start and End and subset the intervals from Type list that satisfying the corresponding conditions on their starts and ends.\n\ndemo_data |&gt; \n  group_by(ID) |&gt; \n  arrange(ID, Begin) |&gt; \n  mutate(\n    findOverlaps = \n      map2_chr(Begin, End, \\(.x, .y) str_c(Type[!(.x &gt;= End | .y &lt;= Begin)], collapse = \" & \"))\n  )\n\n# A tibble: 17 × 5\n# Groups:   ID [5]\n   ID    Begin   End Type  findOverlaps\n   &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;       \n 1 1        12    18 A     A           \n 2 1        20    25 B     B & C       \n 3 1        23    30 C     B & C       \n 4 2         7    13 A     A & B       \n 5 2        12    20 B     A & B       \n 6 3        18    28 A     A & B       \n 7 3        20    33 B     A & B & C   \n 8 3        31    42 C     B & C       \n 9 3        44    50 D     D           \n10 4        10    25 A     A & B & C   \n11 4        15    19 B     A & B       \n12 4        21    30 C     A & C       \n13 5         3     8 A     A & B       \n14 5         7    15 B     A & B & C   \n15 5        13    22 C     B & C & D   \n16 5        19    26 D     C & D & E   \n17 5        25    33 E     D & E       \n\n\n\n\nIndustrial Problem Solving\nGiven patients data on enrollment start, (beginning of follow-up observation) and censoring or death date, we want to compute a timeseries graph showing the total N under observation at a given time.\n\npatient_fup_data &lt;- \n  tibble(\n    ID             = 1:200, \n    startFollowUp  = c(sample(1:200, 100, replace = TRUE), sample(300:500, 100, replace = TRUE)),\n    endDeathCensor = startFollowUp + sample(5:100, 200, replace = TRUE)  \n  )\n\n\nkable(patient_fup_data, n = 10)\n\n\n\n\nID\nstartFollowUp\nendDeathCensor\n\n\n\n\n1\n127\n194\n\n\n2\n78\n116\n\n\n3\n135\n148\n\n\n4\n92\n112\n\n\n5\n164\n242\n\n\n6\n17\n107\n\n\n7\n33\n89\n\n\n8\n177\n226\n\n\n9\n182\n242\n\n\n10\n95\n170\n\n\n11\n149\n240\n\n\n12\n195\n200\n\n\n13\n135\n180\n\n\n14\n54\n116\n\n\n15\n15\n29\n\n\n16\n149\n221\n\n\n17\n135\n174\n\n\n18\n73\n163\n\n\n19\n193\n266\n\n\n20\n58\n87\n\n\n21\n126\n133\n\n\n22\n175\n222\n\n\n23\n104\n109\n\n\n24\n146\n189\n\n\n25\n158\n175\n\n\n26\n89\n98\n\n\n27\n75\n112\n\n\n28\n85\n97\n\n\n29\n86\n163\n\n\n30\n187\n285\n\n\n31\n58\n146\n\n\n32\n70\n95\n\n\n33\n123\n223\n\n\n34\n83\n88\n\n\n35\n24\n40\n\n\n36\n24\n54\n\n\n37\n181\n211\n\n\n38\n162\n258\n\n\n39\n7\n92\n\n\n40\n77\n135\n\n\n41\n80\n107\n\n\n42\n39\n100\n\n\n43\n86\n163\n\n\n44\n53\n82\n\n\n45\n162\n256\n\n\n46\n161\n173\n\n\n47\n9\n89\n\n\n48\n160\n168\n\n\n49\n133\n196\n\n\n50\n150\n178\n\n\n51\n200\n224\n\n\n52\n52\n118\n\n\n53\n72\n146\n\n\n54\n68\n121\n\n\n55\n171\n203\n\n\n56\n56\n134\n\n\n57\n167\n208\n\n\n58\n186\n285\n\n\n59\n118\n198\n\n\n60\n2\n78\n\n\n61\n37\n53\n\n\n62\n10\n47\n\n\n63\n112\n175\n\n\n64\n92\n159\n\n\n65\n66\n105\n\n\n66\n83\n143\n\n\n67\n114\n157\n\n\n68\n189\n223\n\n\n69\n19\n64\n\n\n70\n161\n222\n\n\n71\n176\n214\n\n\n72\n16\n62\n\n\n73\n24\n53\n\n\n74\n186\n191\n\n\n75\n138\n173\n\n\n76\n113\n158\n\n\n77\n142\n216\n\n\n78\n154\n176\n\n\n79\n41\n139\n\n\n80\n93\n160\n\n\n81\n44\n114\n\n\n82\n92\n167\n\n\n83\n115\n130\n\n\n84\n86\n170\n\n\n85\n159\n235\n\n\n86\n9\n27\n\n\n87\n107\n197\n\n\n88\n59\n130\n\n\n89\n121\n152\n\n\n90\n181\n233\n\n\n91\n73\n117\n\n\n92\n148\n192\n\n\n93\n59\n71\n\n\n94\n51\n119\n\n\n95\n57\n107\n\n\n96\n10\n49\n\n\n97\n6\n102\n\n\n98\n169\n219\n\n\n99\n32\n105\n\n\n100\n184\n210\n\n\n101\n348\n398\n\n\n102\n322\n344\n\n\n103\n460\n548\n\n\n104\n437\n486\n\n\n105\n405\n410\n\n\n106\n499\n572\n\n\n107\n450\n533\n\n\n108\n362\n385\n\n\n109\n361\n377\n\n\n110\n435\n503\n\n\n111\n434\n449\n\n\n112\n300\n387\n\n\n113\n466\n477\n\n\n114\n412\n481\n\n\n115\n493\n545\n\n\n116\n500\n590\n\n\n117\n390\n474\n\n\n118\n364\n452\n\n\n119\n492\n585\n\n\n120\n460\n469\n\n\n121\n477\n517\n\n\n122\n311\n348\n\n\n123\n333\n352\n\n\n124\n445\n472\n\n\n125\n326\n387\n\n\n126\n472\n556\n\n\n127\n304\n395\n\n\n128\n468\n553\n\n\n129\n454\n463\n\n\n130\n500\n550\n\n\n131\n495\n515\n\n\n132\n340\n429\n\n\n133\n371\n464\n\n\n134\n452\n505\n\n\n135\n499\n595\n\n\n136\n359\n375\n\n\n137\n412\n429\n\n\n138\n487\n502\n\n\n139\n352\n393\n\n\n140\n311\n397\n\n\n141\n452\n504\n\n\n142\n340\n427\n\n\n143\n416\n448\n\n\n144\n334\n385\n\n\n145\n302\n334\n\n\n146\n400\n448\n\n\n147\n475\n483\n\n\n148\n356\n439\n\n\n149\n407\n496\n\n\n150\n379\n435\n\n\n151\n340\n347\n\n\n152\n360\n446\n\n\n153\n470\n509\n\n\n154\n333\n379\n\n\n155\n324\n418\n\n\n156\n446\n479\n\n\n157\n315\n366\n\n\n158\n358\n395\n\n\n159\n496\n583\n\n\n160\n408\n463\n\n\n161\n410\n440\n\n\n162\n434\n445\n\n\n163\n462\n512\n\n\n164\n382\n444\n\n\n165\n362\n458\n\n\n166\n419\n480\n\n\n167\n336\n370\n\n\n168\n366\n411\n\n\n169\n422\n440\n\n\n170\n488\n533\n\n\n171\n417\n429\n\n\n172\n384\n445\n\n\n173\n372\n423\n\n\n174\n450\n495\n\n\n175\n479\n569\n\n\n176\n409\n415\n\n\n177\n421\n478\n\n\n178\n388\n456\n\n\n179\n464\n509\n\n\n180\n434\n524\n\n\n181\n430\n493\n\n\n182\n314\n408\n\n\n183\n471\n476\n\n\n184\n399\n452\n\n\n185\n331\n391\n\n\n186\n454\n497\n\n\n187\n465\n558\n\n\n188\n397\n454\n\n\n189\n479\n572\n\n\n190\n456\n495\n\n\n191\n333\n408\n\n\n192\n300\n397\n\n\n193\n499\n583\n\n\n194\n306\n393\n\n\n195\n481\n555\n\n\n196\n483\n503\n\n\n197\n488\n528\n\n\n198\n385\n392\n\n\n199\n412\n435\n\n\n200\n471\n551\n\n\n\n\n\n\n\n\nggplot(patient_fup_data) +\n  geom_linerange(\n    aes(xmin = startFollowUp, xmax = endDeathCensor, y = ID)\n    , linewidth = 1) +\n  \n  theme_bw() +\n  \n  theme(\n    axis.text.x = element_text(size = 16, angle = 45),\n    strip.text = element_text(size = 18), \n    axis.title.x = element_text(size = 24),\n    axis.title.y = element_text(size = 24),\n    legend.position = 'right'\n  )\n\n\n\n\nSolution\nWe count in a rolling fashion. Note how multiple patients may enroll at the same time. Then if we want to know the total enroll at that unique entry time, we want to go to the end of the group line, where we have already accumulated everyone…\nOnce we slice, we lose some ID, so drop it. And, the start and end times are just for some arbitrary representative person, so drop them too. We just want the group statistics for the start of each unique enrollment or entry times.\n\nN_under_observation &lt;- \npatient_fup_data |&gt; \n  arrange(startFollowUp) |&gt; \n  \n  mutate(\n    Nenroll = row_number(), \n    Nlost = map_dbl(startFollowUp, \\(.x) sum(endDeathCensor &lt;= .x)), \n    N_obs  = Nenroll - Nlost \n  ) |&gt; \n  \n  \n  group_by(startFollowUp) |&gt; \n  slice(n()) \n\n\nggplot(N_under_observation, aes(x = startFollowUp, y = N_obs)) + \n  geom_step()\n\n\n\n\nHave we missed anything? Yes, ideally, we also want to capture exit times? But it makes the graph more choppy\n\nN_under_observation2 &lt;- \npatient_fup_data |&gt; \n  arrange(endDeathCensor) |&gt; \n  \n  mutate(\n    Nenroll = row_number(), \n    Nlost   = map_dbl(endDeathCensor, \\(.x) sum(endDeathCensor &lt;= .x)), \n    N_obs   = Nenroll - Nlost \n  ) |&gt; \n  \n  \n  group_by(startFollowUp) |&gt; \n  slice(n())"
  },
  {
    "objectID": "posts/gaps-and-islands/post.html",
    "href": "posts/gaps-and-islands/post.html",
    "title": "The Gaps and Islands Problem",
    "section": "",
    "text": "The gaps and islands problem arises from analyzing duration data as commonly captured in databases. Duration data are events recorded with a start datetime and end datetime. Rows in the table correspond to unique events that someone is experiencing, or during which times the event is active. As individuals ID may have one or more event activity, such data are often stored in long-form as date ranges or intervals.\n\n\n\n\n\n\nNote\n\n\n\nFor simplicity, we assume only one type of event under study — the data can be generalized to include an event-type field.\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)\n\nset.seed(12345)\n\n# 10 individuals\nID &lt;- 1:10\n\n# 3 to 7 events per person \nn_events &lt;- sample(3:7, 10, replace = TRUE)\n\nduration_data &lt;- tibble(ID = rep(ID, n_events)) |&gt; \n  mutate(\n    start_date = \n      sample(seq(as.Date('2022-01-01'), as.Date('2022-12-31'), by = \"day\"), n(), replace = TRUE),\n    # 3 days - 2 months episodes \n    end_date = start_date + sample(3:60, n(), replace = TRUE)   \n  ) |&gt; \n  arrange(ID, start_date) |&gt; \n  group_by(ID) |&gt; \n  mutate(eventID = row_number())\n\n\nFor example:\n\nhead(duration_data, n=15) |&gt; kable()\n\n\n\n\nID\nstart_date\nend_date\neventID\n\n\n\n\n1\n2022-02-09\n2022-03-06\n1\n\n\n1\n2022-07-31\n2022-08-09\n2\n\n\n1\n2022-09-14\n2022-11-10\n3\n\n\n1\n2022-10-13\n2022-11-10\n4\n\n\n1\n2022-10-21\n2022-11-23\n5\n\n\n2\n2022-01-12\n2022-02-20\n1\n\n\n2\n2022-01-14\n2022-02-08\n2\n\n\n2\n2022-09-16\n2022-11-03\n3\n\n\n2\n2022-11-24\n2022-12-11\n4\n\n\n3\n2022-01-16\n2022-01-23\n1\n\n\n3\n2022-03-21\n2022-05-05\n2\n\n\n3\n2022-04-16\n2022-05-23\n3\n\n\n3\n2022-05-21\n2022-06-04\n4\n\n\n3\n2022-05-28\n2022-06-23\n5\n\n\n3\n2022-07-11\n2022-08-08\n6\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo reveal the code how to simulate the demo data, click the Code text to expand above.\n\n\nHere, ID 1 experiences 5 distinct eventIDs, with the first one occurring on 2/9 and lasting for 25 days until 3/6. The key observation is that eventID 4 overlaps with eventID 5 within ID 1, where event 5 beginning on 10/21 starts before event 4 has ended on 11/10.\n\n\nVisualizing the date ranges of event occurrences is useful. We plot all individual event date ranges colored by ID, supplying a position_dodge so overlaps are revealed (instead of lying right on top one another).\n\n\nCode\nlibrary(ggplot2)\n\nggplot(duration_data |&gt; filter(ID &lt;= 5),\n       aes(y = factor(ID), xmin = start_date, xmax = end_date, color = factor(ID))) +\n  geom_linerange(position = position_dodge2(width = .5), linewidth = 2) +\n  theme_bw() + \n  xlab(\"Start/ End Dates\") + ylab(\"Individual ID\") +\n  scale_x_date(date_breaks = \"1 month\") + \n  theme(\n    axis.text.x = element_text(size = 16, angle = 45),\n    axis.text.y = element_text(size = 16),\n    axis.title.x = element_text(size = 24),\n    axis.title.y = element_text(size = 24),\n    legend.position = 'none'\n  )\n\n\n\n\n\nDuration patterns by subject\n\n\n\n\n\n\n\nGiven the set-up, how do we want to collapse the data? Our input data is structured as one row per date range per person. The desired output data is one row per coverage interval per person. By coverage, we mean a continuous block of time, defined by a start date and end date, during which the individual is experiencing one or more active events.\n\n\n\n\n\n\nNote\n\n\n\nCoverage intervals are referred to as islands. In-between time periods when there are no events occurring (no date ranges, overlapping or otherwise) are called gaps (holes).\n\n\nFor our demo data, within ID 2, there are 4 eventIDs, but just 3 coverage intervals (islands): some event is active between\n\n2022-01-12 through 2022-02-08 (where the date range of event 2 completely overlaps and within the duration time of event 1)\n2022-09-16 through 2022-11-03 (duration of eventID 3)\n2022-11-24 through 2022-12-11 (duration of last eventID 4)\n\nHence our desired output table will comprise 3 rows for ID 2, with start and end times as described above for each coverage interval. Likewise, by visual inspection, ID 3, who experienced 6 events, will have only 3 coverage intervals as well, with one particularly long coverage interval (of back-to-back events) beginning on 2022-03-21 and finally abating on 2022-06-23.\n\n\n\nExamining the gaps and islands solution can reveal hidden assumptions about data processes or quality issues you might not be aware of. For example, perhaps certain overlap patterns violate assumptions about event frequencies, or some duration lengths and patterns are not physically possible. Typically, the data captured does not reflect the complete story.\nConsider medical databases housing patient medication prescriptions. The table captures PatientID, DispensedDate, and DaysSupply, from which an EndDate is derived representing date of supply depletion relative to dispense time. The data as entered by pharmacists or business administrators for billing purposes or inventory management is only one part of the story, especially if our goal is to understand how patients are treated.\nFor example, suppose we observe multiple overlapping prescriptions for the same medication type (overlapping date ranges), but perhaps differing dose levels. It is not clear whether the patient has been instructed to take both prescriptions simultaneously (effective dose increase), or perhaps to switch to the lower dose before finishing the other prescription. We have missing contextual information! And, if we observe overlapping date ranges among different medication types, we may find new or surprising treatment regimes warranting investigation.\nIf we know what we see is impossible, and we have high assurance of data validity (they were not entered erroneously), we investigate further. Perhaps, it turns out a subset of prescriptions were returned-to-stock and were never picked up by the patient, requiring a check on another data field that we were not aware was being captured. With data in the wild, as we’re removed further away from the source of data origination, incomplete code-books, inaccurate code-books, or non-existent code-books represent the norm.\n\n\n\n\n\n\nNote\n\n\n\nUnless we already know what to look for, generalizing how we describe event patterns can help reveal new information requiring follow-up."
  },
  {
    "objectID": "posts/gaps-and-islands/post.html#visualization",
    "href": "posts/gaps-and-islands/post.html#visualization",
    "title": "The Gaps and Islands Problem",
    "section": "",
    "text": "Visualizing the date ranges of event occurrences is useful. We plot all individual event date ranges colored by ID, supplying a position_dodge so overlaps are revealed (instead of lying right on top one another).\n\n\nCode\nlibrary(ggplot2)\n\nggplot(duration_data |&gt; filter(ID &lt;= 5),\n       aes(y = factor(ID), xmin = start_date, xmax = end_date, color = factor(ID))) +\n  geom_linerange(position = position_dodge2(width = .5), linewidth = 2) +\n  theme_bw() + \n  xlab(\"Start/ End Dates\") + ylab(\"Individual ID\") +\n  scale_x_date(date_breaks = \"1 month\") + \n  theme(\n    axis.text.x = element_text(size = 16, angle = 45),\n    axis.text.y = element_text(size = 16),\n    axis.title.x = element_text(size = 24),\n    axis.title.y = element_text(size = 24),\n    legend.position = 'none'\n  )\n\n\n\n\n\nDuration patterns by subject"
  },
  {
    "objectID": "posts/gaps-and-islands/post.html#what-do-we-wish-to-solve-for",
    "href": "posts/gaps-and-islands/post.html#what-do-we-wish-to-solve-for",
    "title": "The Gaps and Islands Problem",
    "section": "",
    "text": "Given the set-up, how do we want to collapse the data? Our input data is structured as one row per date range per person. The desired output data is one row per coverage interval per person. By coverage, we mean a continuous block of time, defined by a start date and end date, during which the individual is experiencing one or more active events.\n\n\n\n\n\n\nNote\n\n\n\nCoverage intervals are referred to as islands. In-between time periods when there are no events occurring (no date ranges, overlapping or otherwise) are called gaps (holes).\n\n\nFor our demo data, within ID 2, there are 4 eventIDs, but just 3 coverage intervals (islands): some event is active between\n\n2022-01-12 through 2022-02-08 (where the date range of event 2 completely overlaps and within the duration time of event 1)\n2022-09-16 through 2022-11-03 (duration of eventID 3)\n2022-11-24 through 2022-12-11 (duration of last eventID 4)\n\nHence our desired output table will comprise 3 rows for ID 2, with start and end times as described above for each coverage interval. Likewise, by visual inspection, ID 3, who experienced 6 events, will have only 3 coverage intervals as well, with one particularly long coverage interval (of back-to-back events) beginning on 2022-03-21 and finally abating on 2022-06-23."
  },
  {
    "objectID": "posts/gaps-and-islands/post.html#application-in-medicine",
    "href": "posts/gaps-and-islands/post.html#application-in-medicine",
    "title": "The Gaps and Islands Problem",
    "section": "",
    "text": "Examining the gaps and islands solution can reveal hidden assumptions about data processes or quality issues you might not be aware of. For example, perhaps certain overlap patterns violate assumptions about event frequencies, or some duration lengths and patterns are not physically possible. Typically, the data captured does not reflect the complete story.\nConsider medical databases housing patient medication prescriptions. The table captures PatientID, DispensedDate, and DaysSupply, from which an EndDate is derived representing date of supply depletion relative to dispense time. The data as entered by pharmacists or business administrators for billing purposes or inventory management is only one part of the story, especially if our goal is to understand how patients are treated.\nFor example, suppose we observe multiple overlapping prescriptions for the same medication type (overlapping date ranges), but perhaps differing dose levels. It is not clear whether the patient has been instructed to take both prescriptions simultaneously (effective dose increase), or perhaps to switch to the lower dose before finishing the other prescription. We have missing contextual information! And, if we observe overlapping date ranges among different medication types, we may find new or surprising treatment regimes warranting investigation.\nIf we know what we see is impossible, and we have high assurance of data validity (they were not entered erroneously), we investigate further. Perhaps, it turns out a subset of prescriptions were returned-to-stock and were never picked up by the patient, requiring a check on another data field that we were not aware was being captured. With data in the wild, as we’re removed further away from the source of data origination, incomplete code-books, inaccurate code-books, or non-existent code-books represent the norm.\n\n\n\n\n\n\nNote\n\n\n\nUnless we already know what to look for, generalizing how we describe event patterns can help reveal new information requiring follow-up."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "A collection of posts on data management principles using R for the aspiring programmer."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Sieving Data, A Quarto Blog",
    "section": "",
    "text": "Doing iteration with map (when vectorized functions are not enough)\n\n\n\n\n\nApplication to window functions and computing composite scores with missing values\n\n\n\n\n\n\nOct 11, 2023\n\n\n\n\n\n\n  \n\n\n\n\nThe Gaps and Islands Problem\n\n\n\n\n\nAlso known as the overlapping-date-ranges problem, where we study duration data to identify coverage intervals (or, holes)\n\n\n\n\n\n\nOct 4, 2023\n\n\n\n\n\n\n  \n\n\n\n\nTO-DO: Conditional Aggregations\n\n\n\n\n\nConditional aggregations, application in survival analysis\n\n\n\n\n\n\nOct 4, 1999\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/intro-purrr-map/post.html",
    "href": "posts/intro-purrr-map/post.html",
    "title": "Doing iteration with map (when vectorized functions are not enough)",
    "section": "",
    "text": "Functions in the tidyverse suite of libraries are typically vectorized. They know how to process vector (or list) arguments and return a vector (list) output. This means we get looping-behavior for free without having to explicitly program the looping structure.\n\n\n\n\n\n\nNote\n\n\n\nIn R, vectors are special cases of lists where all elements in the list are of the same atomic type (dbl, char, logical, etc.) — i.e., when they do not hold further objects (or other lists).\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)\n\nset.seed(12345)\n\ndemo_data &lt;- \n  tribble(\n    ~ \"X\", ~ \"Y\", ~ \"Z\",\n    3, 8, 5,\n    2, 4, 7,\n    6, 3, 8,\n    1, 5, 2\n  )\n\n\nFor example, consider the follow demo data:\n\nkable(demo_data)\n\n\n\n\nX\nY\nZ\n\n\n\n\n3\n8\n5\n\n\n2\n4\n7\n\n\n6\n3\n8\n\n\n1\n5\n2\n\n\n\n\n\n\n\nSuppose we want to create a new variable W on the data.frame defined as follows:\n\nif X is less than Y, then W = Z\notherwise, W = 2 * Z\n\nWe can achieve this using the vectorized if_else function wrapped around the mutate method for column creation. Let’s also create the sum of X and Y into V\n\ndemo_data |&gt; \n  mutate(\n    W = if_else(X &lt; Y, Z, 2 * Z),\n    V = X + Y\n  ) |&gt;\n        kable()\n\n\n\n\nX\nY\nZ\nW\nV\n\n\n\n\n3\n8\n5\n5\n11\n\n\n2\n4\n7\n7\n6\n\n\n6\n3\n8\n16\n9\n\n\n1\n5\n2\n2\n6"
  },
  {
    "objectID": "posts/intro-purrr-map/post.html#thresholding-and-counting",
    "href": "posts/intro-purrr-map/post.html#thresholding-and-counting",
    "title": "Doing iteration with map (when vectorized functions are not enough)",
    "section": "Thresholding and counting",
    "text": "Thresholding and counting\nWe demonstrate with a simple application to thresholding. Suppose we have a list of values X, and a smaller list of thresholding values T\n\nlibrary(purrr)\n\nX = c(3, 7, 10, 3, 14, 20, 11, 27)\nT = c(3, 10, 15, 22)\n\nWe want to know, at some threshold of interest, how many values in X fall below the threshold. For the first threshold value 3, we can answer using sum with the vectorized predicate &lt;\n\nX &lt; 3\n\n[1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\nsum(X &lt; 3)\n\n[1] 0\n\n\nNow to achieve this for all values in our threshold list, we use map_dbl — the first argument is the list input we want to loop over (threshold values), and the second argument is a anonymous function over X and the threshold argument .t. The final result here will match the dimensions of the argument list that we want to run the function over.\n\nmap_dbl(T, \\(.t) sum(X &lt; .t))\n\n[1] 0 3 6 7\n\n\n\n\n\n\n\n\nTip\n\n\n\nAn anonymous function, one without a name, is defined in R by \\(.argument) { .body }. Functions are first-class citizens, meaning they can be passed around as arguments into yet other functions."
  },
  {
    "objectID": "posts/intro-purrr-map/post.html#map-for-window-aggregations",
    "href": "posts/intro-purrr-map/post.html#map-for-window-aggregations",
    "title": "Doing iteration with map (when vectorized functions are not enough)",
    "section": "Map for window aggregations",
    "text": "Map for window aggregations\nSuppose our set of tasks are to compute at each scheduled visit\n\nThe average all X values taken within the last 30 days (rolling average of available values)\nThe maximum Y value recorded so far, but excluded the current Y\nThe current value of Z, or the most recent one recorded within the last 10 days\n\n\npatient_visit_with_window_summary &lt;- patient_visit_data |&gt; \n  \n  group_by(ID) |&gt; \n  mutate(\n    \n1    X_30day_average =\n      map_dbl(VisitDate, \n        \\(.v) mean(X[VisitDate &lt;= .v & VisitDate &gt;= .v - 30], na.rm = TRUE)),\n    \n2    Y_max =\n      map_dbl(VisitDate, \n        \\(.v) max(Y[VisitDate &lt;= .v], na.rm = TRUE)),\n    \n3    Z_recent =\n      map_dbl(VisitDate, \n        \\(.v) last(Z[VisitDate &lt;= .v & VisitDate &gt;= .v - 10], na_rm = TRUE))\n    )\n\n\n1\n\n30 day average of X\n\n2\n\nCumulative maximum of Y\n\n3\n\nMost recent `Z within the last 10 days\n\n\n\n\nFor each variable, we use map_dbl where the first argument is the VisitDate column (processed within patient) that we want to iterate over as inputs. The user-defined anonymous functions passed into the second argument of map_dbl are functions of the global variables X, Y, or Z, subset by VisitDate (also scoped separately from the data.frame context) and the dummy variable .v. They eventually reduce the filtered variables using the aggregation functions mean, max, and last.\n\n\nCode\npatient_visit_with_window_summary |&gt; filter(ID == 3 | ID == 7) |&gt;\n  kable(n = 20) |&gt; column_spec(1:7, border_left = TRUE, border_right = TRUE)\n\n\n\n\n\nID\nVisitDate\nX\nY\nZ\nX_30day_average\nY_max\nZ_recent\n\n\n\n\n3\n2022-01-03\n39\nNA\n53\n39.00000\n-Inf\n53\n\n\n3\n2022-01-07\nNA\n105\n53\n39.00000\n105\n53\n\n\n3\n2022-02-24\n16\n78\n49\n16.00000\n105\n49\n\n\n3\n2022-02-25\n35\n109\n50\n25.50000\n109\n50\n\n\n3\n2022-03-27\n48\nNA\n40\n41.50000\n109\n40\n\n\n3\n2022-04-04\n30\n94\n47\n39.00000\n109\n47\n\n\n3\n2022-04-08\n37\n63\nNA\n38.33333\n109\n47\n\n\n3\n2022-04-09\n28\nNA\n52\n35.75000\n109\n52\n\n\n3\n2022-05-25\n36\n103\nNA\n36.00000\n109\nNA\n\n\n3\n2022-06-01\nNA\n89\nNA\n36.00000\n109\nNA\n\n\n7\n2022-01-18\n35\n91\n55\n35.00000\n91\n55\n\n\n7\n2022-02-01\n24\n44\n46\n29.50000\n91\n46\n\n\n7\n2022-02-27\n35\n73\nNA\n29.50000\n91\nNA\n\n\n7\n2022-04-06\n26\n90\n56\n26.00000\n91\n56\n\n\n7\n2022-04-26\n24\n102\n51\n25.00000\n102\n51\n\n\n7\n2022-05-01\nNA\n88\nNA\n25.00000\n102\n51\n\n\n7\n2022-05-12\nNA\n92\nNA\n24.00000\n102\nNA\n\n\n7\n2022-05-15\n56\n90\nNA\n40.00000\n102\nNA\n\n\n7\n2022-05-28\nNA\n64\n54\n56.00000\n102\n54\n\n\n7\n2022-06-16\nNA\n89\n46\nNaN\n102\n46\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen supplying arguments for na.rm or na_rm, always provide the full values TRUE or FALSE instead of using the abbreviated shortcut T or F.\n\n\nTo help spot-check the results (particularly for the rolling 30-day look-back averages), use the general map to get a list of values meeting the condition at each visit (list of lists!) prior to aggregation by mean. For Z_recent, you may want to validate that the 10-day look-back is working as expected.\n\npatient_visit_with_window_summary &lt;- patient_visit_data |&gt; \n  \n  group_by(ID) |&gt;\n  \n  mutate(\n    \n1    Xs_30day = map(VisitDate, \\(.v) X[VisitDate &lt;= .v & VisitDate &gt;= .v - 30]),\n    \n    X_30day_average = \n      map_dbl(VisitDate, \n        \\(.v) mean(X[VisitDate &lt;= .v & VisitDate &gt;= .v - 30], na.rm = TRUE)),\n    \n    Y_max = \n      map_dbl(VisitDate, \n        \\(.v) max(Y[VisitDate &lt;= .v], na.rm = TRUE)),\n    \n    Z_recent = \n      map_dbl(VisitDate, \n        \\(.v) last(Z[VisitDate &lt;= .v & VisitDate &gt;= .v - 10], na_rm = TRUE))\n    \n    ) \n\n\n1\n\nNow our anonymous function filters X using the VisitDate column and the index visit date .v, but does not summarize the vector further. Instead of returning a dbl value at each execution (like map_dbl), it must return back an entire list at each call. Hence, in the end map returns a vector of lists.\n\n\n\n\n\n\nCode\npatient_visit_with_window_summary |&gt; filter(ID == 3 | ID == 7) |&gt;\n    kable(n = 20) |&gt; column_spec(1:8, border_left = TRUE, border_right = TRUE)\n\n\n\n\n\nID\nVisitDate\nX\nY\nZ\nXs_30day\nX_30day_average\nY_max\nZ_recent\n\n\n\n\n3\n2022-01-03\n39\nNA\n53\n39\n39.00000\n-Inf\n53\n\n\n3\n2022-01-07\nNA\n105\n53\n39, NA\n39.00000\n105\n53\n\n\n3\n2022-02-24\n16\n78\n49\n16\n16.00000\n105\n49\n\n\n3\n2022-02-25\n35\n109\n50\n16, 35\n25.50000\n109\n50\n\n\n3\n2022-03-27\n48\nNA\n40\n35, 48\n41.50000\n109\n40\n\n\n3\n2022-04-04\n30\n94\n47\n48, 30\n39.00000\n109\n47\n\n\n3\n2022-04-08\n37\n63\nNA\n48, 30, 37\n38.33333\n109\n47\n\n\n3\n2022-04-09\n28\nNA\n52\n48, 30, 37, 28\n35.75000\n109\n52\n\n\n3\n2022-05-25\n36\n103\nNA\n36\n36.00000\n109\nNA\n\n\n3\n2022-06-01\nNA\n89\nNA\n36, NA\n36.00000\n109\nNA\n\n\n7\n2022-01-18\n35\n91\n55\n35\n35.00000\n91\n55\n\n\n7\n2022-02-01\n24\n44\n46\n35, 24\n29.50000\n91\n46\n\n\n7\n2022-02-27\n35\n73\nNA\n24, 35\n29.50000\n91\nNA\n\n\n7\n2022-04-06\n26\n90\n56\n26\n26.00000\n91\n56\n\n\n7\n2022-04-26\n24\n102\n51\n26, 24\n25.00000\n102\n51\n\n\n7\n2022-05-01\nNA\n88\nNA\n26, 24, NA\n25.00000\n102\n51\n\n\n7\n2022-05-12\nNA\n92\nNA\n24, NA, NA\n24.00000\n102\nNA\n\n\n7\n2022-05-15\n56\n90\nNA\n24, NA, NA, 56\n40.00000\n102\nNA\n\n\n7\n2022-05-28\nNA\n64\n54\nNA, NA, 56, NA\n56.00000\n102\n54\n\n\n7\n2022-06-16\nNA\n89\n46\nNA, NA\nNaN\n102\n46"
  },
  {
    "objectID": "posts/intro-purrr-map/post.html#composite-scores-with-missing-values",
    "href": "posts/intro-purrr-map/post.html#composite-scores-with-missing-values",
    "title": "Doing iteration with map (when vectorized functions are not enough)",
    "section": "Composite scores with missing values",
    "text": "Composite scores with missing values\nWe want to compute and track some composite score at each visit. We would like to use the value taken at the visit time, but we’re willing to impute with the closest value 30 days prior. Our composite measure is \\(X + Y\\).\n\npatient_visit_data |&gt; \n1  group_by(ID) |&gt;\n  mutate(\n2    XplusY = map_dbl(VisitDate,\n3      \\(.v)\n        last(\n4          X[VisitDate &lt;= .v & VisitDate &gt;= .v - 30], na_rm = TRUE)\n        +\n        last(\n          Y[VisitDate &lt;= .v & VisitDate &gt;= .v - 30], na_rm = TRUE))\n    \n    ) |&gt; \n  \n5  filter(ID == 2 | ID == 8) |&gt;\n  kable(n = 20)\n\n\n1\n\nTransform the data by processing the variables within patient\n\n\n2\n\nUsing map_dbl to make our composite score of X and Y. Its first argument is the VisitDate column — the list of values we want to loop through or use as input values to our user-defined function\n\n3\n\nThe head of our user-defined function, which will be represented as an anonymous function passed entirely into the second argument of map_dbl. The function of dummy variable .v that will be drawn from the input list\n\n4\n\nThe body of our user-defined anonymous function. Observe it’s a function of the environment variables X and VisitDate taken from the data.frame context. Note VisitDate used here is independent and different from its used also in map_dbl!\n\n5\n\nExamine the outputs for patients 2 and 8\n\n\n\n\n\n\n\nID\nVisitDate\nX\nY\nZ\nXplusY\n\n\n\n\n2\n2022-01-12\n24\n92\n48\n116\n\n\n2\n2022-01-15\n34\n113\n47\n147\n\n\n2\n2022-02-20\nNA\n103\n50\nNA\n\n\n2\n2022-03-03\nNA\nNA\nNA\nNA\n\n\n2\n2022-03-15\nNA\n93\n48\nNA\n\n\n2\n2022-04-13\nNA\nNA\n52\nNA\n\n\n2\n2022-05-04\n9\nNA\n55\nNA\n\n\n2\n2022-05-13\n31\nNA\nNA\nNA\n\n\n2\n2022-06-25\n28\n88\nNA\n116\n\n\n2\n2022-06-28\n44\nNA\n59\n132\n\n\n8\n2022-01-02\nNA\nNA\nNA\nNA\n\n\n8\n2022-01-11\n24\n74\n56\n98\n\n\n8\n2022-01-25\n28\nNA\n41\n102\n\n\n8\n2022-02-03\n40\n93\n59\n133\n\n\n8\n2022-02-07\nNA\nNA\n50\n133\n\n\n8\n2022-04-16\n5\n66\n52\n96\n\n\n8\n2022-04-16\n30\nNA\n49\n96\n\n\n8\n2022-05-12\n42\n93\n49\n135\n\n\n8\n2022-05-15\nNA\n102\n52\n144\n\n\n8\n2022-05-23\n27\nNA\nNA\n129\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe function last has an argument called na_rm with default value False. Here, we want the last available measurement recorded when sorted by descending date — which will correspond to the most recent record."
  }
]